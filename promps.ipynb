{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando generador de prompts para SDXL Refiner 1.0\n",
      "Archivo de entrada: stratify.csv\n",
      "Utilizando 2 GPUs con tamaño de batch: 50\n",
      "Guardando progreso cada 50 filas\n",
      "Procesando un máximo de 200 filas para prueba\n",
      "Verificando archivo de entrada...\n",
      "Limitando a 200 filas para prueba\n",
      "Total de filas a procesar: 200\n",
      "GPU 0 procesará filas 0 a 99\n",
      "GPU 1 procesará filas 100 a 199\n",
      "Eliminado archivo previo: resultados_sdxl/output_gpu1.csv\n",
      "GPU 1 - Procesando batch 1/2\n",
      "Eliminado archivo previo: resultados_sdxl/output_gpu0.csv\n",
      "GPU 0 - Procesando batch 1/2\n",
      "GPU 1 - Procesado 110/50 del batch actual (total: 110)\n",
      "GPU 0 - Procesado 10/50 del batch actual (total: 10)\n",
      "GPU 1 - Procesado 120/50 del batch actual (total: 120)\n",
      "GPU 0 - Procesado 20/50 del batch actual (total: 20)\n",
      "GPU 1 - Procesado 130/50 del batch actual (total: 130)\n",
      "GPU 0 - Procesado 30/50 del batch actual (total: 30)\n",
      "GPU 1 - Procesado 140/50 del batch actual (total: 140)\n",
      "GPU 1 - Procesado 150/50 del batch actual (total: 150)\n",
      "GPU 1 - Guardando progreso, 50 filas procesadas\n",
      "Archivo creado: resultados_sdxl/output_gpu1.csv (50 filas)\n",
      "GPU 1 - Procesando batch 2/2\n",
      "GPU 0 - Procesado 40/50 del batch actual (total: 40)\n",
      "GPU 1 - Procesado 160/50 del batch actual (total: 210)\n",
      "GPU 0 - Procesado 50/50 del batch actual (total: 50)\n",
      "GPU 0 - Guardando progreso, 50 filas procesadas\n",
      "Archivo creado: resultados_sdxl/output_gpu0.csv (50 filas)\n",
      "GPU 0 - Procesando batch 2/2\n",
      "GPU 1 - Procesado 170/50 del batch actual (total: 220)\n",
      "GPU 1 - Procesado 180/50 del batch actual (total: 230)\n",
      "GPU 0 - Procesado 60/50 del batch actual (total: 110)\n",
      "GPU 1 - Procesado 190/50 del batch actual (total: 240)\n",
      "GPU 1 - Procesado 200/50 del batch actual (total: 250)\n",
      "GPU 1 - Guardando progreso, 100 filas procesadas\n",
      "Archivo actualizado: resultados_sdxl/output_gpu1.csv (total: 100 filas)\n",
      "GPU 0 - Procesado 70/50 del batch actual (total: 120)\n",
      "GPU 0 - Procesado 80/50 del batch actual (total: 130)\n",
      "GPU 0 - Procesado 90/50 del batch actual (total: 140)\n",
      "GPU 0 - Procesado 100/50 del batch actual (total: 150)\n",
      "GPU 0 - Guardando progreso, 100 filas procesadas\n",
      "Archivo actualizado: resultados_sdxl/output_gpu0.csv (total: 100 filas)\n",
      "Combinando resultados finales...\n",
      "Procesamiento completado. Resultados finales:\n",
      "  - GPU 0: resultados_sdxl/output_gpu0.csv (0.06 MB)\n",
      "  - GPU 1: resultados_sdxl/output_gpu1.csv (0.06 MB)\n",
      "  - Combinado: resultados_sdxl/combined_output.csv (0.12 MB)\n",
      "Total de filas procesadas: 200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from together import Together\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de logging con path absoluto\n",
    "log_file = os.path.abspath('togetherDiego.log')\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Inicializar cliente de Together AI\n",
    "client = Together(api_key=\"\")\n",
    "\n",
    "\n",
    "def get_system_prompt(change_level):\n",
    "    \"\"\"Genera un prompt de sistema detallado según el nivel de cambio.\"\"\"\n",
    "    base_prompt = \"\"\"You are an expert in image-to-image modification with Stable Diffusion XL.\n",
    "Create a prompt that produces a {change_level} level of change compared to the original image.\n",
    "Focus on creating a high-quality, detailed prompt for SDXL Refiner 1.0.\n",
    "Do not include references to the original artist, painting name, or description in the output.\"\"\"\n",
    "\n",
    "    level_prompts = {\n",
    "    \"subtle\": \"\"\"\n",
    "For this SUBTLE modification:\n",
    "- Maintain the exact composition, subject matter, and artistic intention\n",
    "- Make minimal adjustments to color temperature, lighting intensity, or texture details\n",
    "- Ensure the modified image would be recognized as nearly identical to the original\n",
    "- Focus on enhancing rather than changing elements\n",
    "- Consider appropriate techniques like increasing detail, adjusting contrast, or enhancing textures\n",
    "\n",
    "Keywords to consider: refine, enhance, subtle shift, gentle adjustment, nuanced change, detailed, crisp, high-quality\"\"\",\n",
    "    \n",
    "    \"moderate\": \"\"\"\n",
    "For this MODERATE modification:\n",
    "- Keep the main composition and subject recognizable\n",
    "- Transform color schemes, lighting conditions, or artistic techniques\n",
    "- Add or modify secondary elements while preserving primary subjects\n",
    "- Create a clear visual difference while maintaining the artwork's essence\n",
    "- Consider time of day changes, season shifts, or stylistic reinterpretations\n",
    "\n",
    "Keywords to consider: transform, shift, reinterpret, reimagine, alternative take, artistic variation\"\"\",\n",
    "    \n",
    "    \"radical\": \"\"\"\n",
    "For this RADICAL modification:\n",
    "- Completely transform the artistic style, era, or medium\n",
    "- Dramatically alter color palette, composition, or perspective\n",
    "- Recontextualize the subject matter in a boldly different setting\n",
    "- Create a new artistic vision that only conceptually relates to the original\n",
    "- Consider genre shifts, opposing aesthetics, or unexpected conceptual fusions\n",
    "\n",
    "Keywords to consider: revolutionize, transpose, transmute, overhaul, profound transformation, reimagined universe\"\"\"\n",
    "    }\n",
    "    \n",
    "    return base_prompt.format(change_level=change_level) + level_prompts[change_level] + \"\\n\\nCreate a detailed, vibrant prompt with descriptive adjectives. MAXIMUM 75 WORDS.\"\n",
    "\n",
    "def generate_prompt(row, row_idx):\n",
    "    \"\"\"Genera un prompt para Stable Diffusion usando el modelo LLM de Together AI.\"\"\"\n",
    "    change_level = row['category'].lower()\n",
    "    system_prompt = get_system_prompt(change_level)\n",
    "    \n",
    "    # Información contextual de la pintura\n",
    "    art_context = f\"\"\"Genre: {row['genre']}\n",
    "    Artist: {row['artist']}\n",
    "    Title: {row['painting_name']}\n",
    "    Description: {row['description']}\n",
    "    Change level: {change_level}\n",
    "\n",
    "    Generate a prompt for Stable Diffusion XL Refiner 1.0 to create a variation of this artwork.\"\"\"\n",
    "    \n",
    "    # Construir el mensaje completo para Together AI\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": art_context}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Enviar la solicitud a Together AI\n",
    "        logging.info(f\"Enviando solicitud para fila {row_idx}: {row['painting_name']}\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-3-8b-chat-hf\",\n",
    "            messages=messages,\n",
    "            max_tokens=200  \n",
    "        )\n",
    "        \n",
    "        # Obtener el prompt generado\n",
    "        generated_prompt = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Mejorar el logging para incluir el prompt generado\n",
    "        logging.info(f\"Prompt generado para fila {row_idx}: {generated_prompt}\")\n",
    "        \n",
    "        return generated_prompt\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en fila {row_idx}: {str(e)}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "def process_csv(file_path, output_file, batch_size=50, delay=1):\n",
    "    \"\"\"Procesa un archivo CSV para generar prompts y guardar los resultados en lotes.\"\"\"\n",
    "    # Convertir a rutas absolutas\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    output_file = os.path.abspath(output_file)\n",
    "    \n",
    "    # Crear directorio para resultados si no existe\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Leer el archivo CSV original\n",
    "    df = pd.read_csv(file_path)\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    logging.info(f\"Iniciando procesamiento de {total_rows} filas desde {file_path}\")\n",
    "    print(f\"Iniciando procesamiento de {total_rows} filas desde {file_path}\")\n",
    "    \n",
    "    # Verificar si ya existe un archivo de salida para continuar el proceso\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_csv(output_file)\n",
    "        processed_rows = len(existing_df)\n",
    "        logging.info(f\"Archivo de salida existente con {processed_rows} filas procesadas\")\n",
    "        print(f\"Archivo de salida existente con {processed_rows} filas procesadas\")\n",
    "        \n",
    "        # Verificar si todas las filas han sido procesadas\n",
    "        if processed_rows >= total_rows:\n",
    "            logging.info(\"Todas las filas ya han sido procesadas. No se requiere más procesamiento.\")\n",
    "            print(\"Todas las filas ya han sido procesadas. No se requiere más procesamiento.\")\n",
    "            return\n",
    "        \n",
    "        # Continuar desde donde se dejó\n",
    "        df = df.iloc[processed_rows:]\n",
    "        start_idx = processed_rows\n",
    "    else:\n",
    "        # Iniciar desde cero\n",
    "        existing_df = pd.DataFrame()  # Crear DataFrame vacío en lugar de None\n",
    "        start_idx = 0\n",
    "    \n",
    "    results = []\n",
    "    current_batch = 0\n",
    "    last_save_time = time.time()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            real_idx = start_idx + (idx - df.index[0])\n",
    "            prompt = generate_prompt(row, real_idx)\n",
    "            \n",
    "            # Crear un diccionario con los datos originales y el prompt generado\n",
    "            row_data = row.to_dict()\n",
    "            row_data['generated_prompt'] = prompt\n",
    "            results.append(row_data)\n",
    "            \n",
    "            # Mostrar el prompt generado\n",
    "            print(f\"Row {real_idx}: {prompt}\")\n",
    "            \n",
    "            # Guardar resultados periódicamente según batch_size o tiempo (cada 10 minutos)\n",
    "            current_batch += 1\n",
    "            current_time = time.time()\n",
    "            time_elapsed = current_time - last_save_time\n",
    "            \n",
    "            if current_batch >= batch_size or time_elapsed > 600:  # 600 segundos = 10 minutos\n",
    "                # Genera un timestamp único para el backup\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                \n",
    "                # Guardar resultados\n",
    "                save_results(results, existing_df, output_file, timestamp)\n",
    "                \n",
    "                # Actualizar existing_df con los nuevos resultados\n",
    "                new_df = pd.DataFrame(results)\n",
    "                existing_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "                \n",
    "                logging.info(f\"Guardados {len(results)} resultados en lote (filas {real_idx-current_batch+1} a {real_idx})\")\n",
    "                print(f\"Guardados {len(results)} resultados en lote (filas {real_idx-current_batch+1} a {real_idx})\")\n",
    "                \n",
    "                results = []  # Reiniciar para el próximo lote\n",
    "                current_batch = 0\n",
    "                last_save_time = current_time\n",
    "            \n",
    "            # Respetar el límite de RPM\n",
    "            time.sleep(delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error general al procesar la fila {real_idx}: {str(e)}\"\n",
    "            logging.error(error_msg)\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Agregar fila con error\n",
    "            row_data = row.to_dict()\n",
    "            row_data['generated_prompt'] = f\"ERROR: {str(e)}\"\n",
    "            results.append(row_data)\n",
    "            \n",
    "            # Si ocurre un error, guardar lo que tenemos hasta ahora\n",
    "            if len(results) > 0:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                save_results(results, existing_df, output_file, timestamp)\n",
    "                \n",
    "                # Actualizar existing_df\n",
    "                new_df = pd.DataFrame(results)\n",
    "                existing_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "                \n",
    "                logging.info(f\"Guardados {len(results)} resultados después de error\")\n",
    "                print(f\"Guardados {len(results)} resultados después de error\")\n",
    "                results = []\n",
    "                current_batch = 0\n",
    "                last_save_time = time.time()\n",
    "    \n",
    "    # Guardar cualquier resultado restante\n",
    "    if results:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_results(results, existing_df, output_file, timestamp)\n",
    "        logging.info(f\"Guardados {len(results)} resultados finales\")\n",
    "        print(f\"Guardados {len(results)} resultados finales\")\n",
    "    \n",
    "    logging.info(f\"Procesamiento completo. Resultados guardados en {output_file}\")\n",
    "    print(f\"Procesamiento completo. Resultados guardados en {output_file}\")\n",
    "\n",
    "def save_results(new_results, existing_df, output_file, timestamp):\n",
    "    \"\"\"Guarda los resultados en el archivo CSV, concatenando con datos existentes.\"\"\"\n",
    "    if not new_results:\n",
    "        logging.info(\"No hay nuevos resultados para guardar\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Convertir resultados a DataFrame\n",
    "        new_df = pd.DataFrame(new_results)\n",
    "        \n",
    "        # Concatenar con datos existentes\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        \n",
    "        # Guardar el DataFrame combinado\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Guardado principal completado: {output_file}\")\n",
    "        \n",
    "        # También guardar una copia de respaldo con timestamp\n",
    "        backup_dir = os.path.join(os.path.dirname(output_file), \"backups\")\n",
    "        if not os.path.exists(backup_dir):\n",
    "            os.makedirs(backup_dir)\n",
    "            \n",
    "        backup_file = os.path.join(backup_dir, f\"{os.path.basename(output_file).split('.')[0]}_{timestamp}.csv\")\n",
    "        combined_df.to_csv(backup_file, index=False)\n",
    "        logging.info(f\"Backup completado: {backup_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "        print(f\"Error al guardar resultados: {str(e)}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Rutas absolutas para mayor seguridad\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    input_csv = os.path.join(base_dir, \"parte_1.csv\") \n",
    "    output_dir = os.path.join(base_dir, \"together\")\n",
    "    \n",
    "    # Asegurar que el directorio de salida exista\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    output_csv = os.path.join(output_dir, \"togetherDiego.csv\")\n",
    "    \n",
    "    # Reducir el tamaño del lote y agregar más puntos de guardado\n",
    "    process_csv(input_csv, output_csv, batch_size=50, delay=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
